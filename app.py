import streamlit as st
import time
from pyspark.sql import SparkSession
from pyspark.sql.functions import rand
import pandas as pd
from pyspark.sql import functions as F
from pyspark.ml import PipelineModel

# Configuration Constants (Consider moving to a separate config file or environment variables)
SPARK_APP_NAME = "BreweryQualityApp"
SPARK_DRIVER_MEMORY = "8g"
SPARK_EXECUTOR_MEMORY = "8g"
MODEL_PATH = "/home/entropiadev/models/brewery_pipeline"
DATA_PATH = "./data/brewery_sales.parquet"
SIMULATION_BATCH_SIZE = 5
SIMULATION_SLEEP_INTERVAL = 2  # seconds

def initialize_spark_session():
    """Initializes and returns a Spark session with predefined configurations."""
    spark = (SparkSession.builder.
               appName(SPARK_APP_NAME).
               config("spark.driver.memory", SPARK_DRIVER_MEMORY).
               config("spark.executor.memory", SPARK_EXECUTOR_MEMORY).
               getOrCreate())
    return spark

def load_model(model_path: str):
    """
    Loads the pre-trained machine learning model from the specified path.
    
    Args:
        model_path (str): The file system path to the saved PipelineModel.
        
    Returns:
        PipelineModel: The loaded machine learning model.
    """
    model = PipelineModel.load(model_path)
    return model

def load_and_preprocess_data(spark_session: SparkSession, data_path: str):
    """
    Loads brewery sales data from a Parquet file and preprocesses it.
    
    Preprocessing steps include:
    - Splitting the 'Ingredient_Ratio' column into 'Malt_Ratio', 'Hop_Ratio', and 'Yeast_Ratio'.
    - Converting the 'Brew_Date' column to a date type.
    
    Args:
        spark_session (SparkSession): The active Spark session.
        data_path (str): The path to the Parquet file containing brewery sales data.
        
    Returns:
        DataFrame: The preprocessed Spark DataFrame.
    """
    df_full = spark_session.read.parquet(data_path)

    # Split ingredient ratio string into separate numeric columns
    df_full = (df_full
          .withColumn("ratio_arr", F.split(F.col("Ingredient_Ratio"), ":"))
          .withColumn("Malt_Ratio" , F.col("ratio_arr").getItem(0).cast("double"))
          .withColumn("Hop_Ratio"  , F.col("ratio_arr").getItem(1).cast("double"))
          .withColumn("Yeast_Ratio", F.col("ratio_arr").getItem(2).cast("double"))
          .drop("Ingredient_Ratio", "ratio_arr")  # Drop original and temporary columns
    )

    # Convert Brew_Date to date type
    df_full = df_full.withColumn("Brew_Date", F.to_date("Brew_Date"))
    return df_full

# Feature columns used for model prediction (excluding target or identifier columns if any)
# This list should match the features the model was trained on.
FEATURE_COLS = [
    "Fermentation_Time", "Temperature", "pH_Level", "Gravity",
    "Alcohol_Content", "Bitterness", "Color",
    "Malt_Ratio", "Hop_Ratio", "Yeast_Ratio",
    "Loss_During_Brewing", "Loss_During_Fermentation", "Loss_During_Bottling_Kegging"
]

def process_batch(df_full_data: pd.DataFrame, model_pipeline: PipelineModel, batch_size: int):
    """
    Processes a random batch of data using the loaded model.
    
    Steps:
    1. Takes a random sample (micro-batch) from the full dataset.
    2. Makes predictions using the provided model pipeline.
    3. Selects relevant columns for display.
    
    Args:
        df_full_data (DataFrame): The full Spark DataFrame to sample from.
        model_pipeline (PipelineModel): The trained ML model.
        batch_size (int): The number of rows to include in the micro-batch.
        
    Returns:
        DataFrame: A Spark DataFrame containing the input features and predictions for the batch.
    """
    # Take a random micro-batch of specified size
    df_batch = df_full_data.orderBy(rand()).limit(batch_size)

    # Make predictions
    df_batch_predictions = model_pipeline.transform(df_batch)
    
    # Select columns for display (original features + prediction)
    # Note: Ensure 'prediction' is the actual output column name from your model.
    columns_to_display = FEATURE_COLS + ["Brew_Date", "prediction"] # Add Brew_Date and prediction
    
    # Filter out any columns that might not exist in df_batch_predictions if FEATURE_COLS is too broad
    # Or, more robustly, select only columns that are present in df_batch_predictions.
    # For this example, we assume all FEATURE_COLS plus Brew_Date and prediction are in df_batch_predictions.
    df_display = df_batch_predictions.select(columns_to_display)
    
    return df_display

def main_app():
    """
    Main function to run the Streamlit application for Brewery Quality Control.
    
    Initializes the UI, loads data and model, and runs the simulation loop
    to display real-time quality predictions.
    """
    # Configure Streamlit page settings
    st.set_page_config(layout="wide", page_title="Control de Calidad de Cervecer√≠a")
    st.title("Panel de Control de Calidad de Cervecer√≠a")

    # Application sidebar for controls and information
    st.sidebar.header("Controles de Simulaci√≥n")
    
    # Informaci√≥n sobre la aplicaci√≥n
    with st.sidebar.expander("‚ÑπÔ∏è Acerca de esta aplicaci√≥n"):
        st.write("""
        Este panel de control permite monitorear en tiempo real la calidad de los lotes de cerveza en producci√≥n. 
        Utiliza un modelo de aprendizaje autom√°tico entrenado con datos hist√≥ricos para predecir la calidad del producto.
        
        **Caracter√≠sticas principales:**
        - Monitoreo en tiempo real de variables cr√≠ticas
        - Predicciones autom√°ticas de calidad por lote
        - Sistema de alertas tempranas
        - Visualizaci√≥n de tendencias y patrones
        - Registro autom√°tico de incidencias
        
        **Integraci√≥n con sistemas de producci√≥n:**
        - Conexi√≥n directa con sensores de l√≠nea
        - Sincronizaci√≥n con sistema MES
        - Registro en base de datos central
        - Exportaci√≥n autom√°tica de reportes
        """)
    
    # Gu√≠a de interpretaci√≥n
    with st.sidebar.expander("üìä Gu√≠a de interpretaci√≥n"):
        st.write("""
        **Puntuaci√≥n de Calidad:**
        - 0.8 - 1.0: Calidad √ìptima ‚úÖ
          *Producci√≥n normal, no se requieren ajustes*
        - 0.6 - 0.8: Calidad Aceptable üü°
          *Revisar tendencias y considerar ajustes preventivos*
        - < 0.6: Requiere Revisi√≥n üî¥
          *Activar protocolo de control de calidad*
        
        **Rangos Aceptables por Variable:**
        - Temperatura: 18-22¬∞C
        - pH: 4.0-6.0
        - Gravedad: 1.010-1.020
        - Tiempo de Fermentaci√≥n: 72-96h
        
        Los valores se actualizan cada {} segundos con datos de {} lotes.
        """.format(SIMULATION_SLEEP_INTERVAL, SIMULATION_BATCH_SIZE))
    
    # Procedimientos de emergencia
    with st.sidebar.expander("üö® Procedimientos de emergencia"):
        st.write("""
        **En caso de alerta de calidad:**
        1. Pausar la l√≠nea de producci√≥n inmediatamente
        2. Tomar muestras manuales del √∫ltimo lote
        3. Contactar al supervisor de calidad
        4. Documentar el incidente en el sistema
        5. Iniciar protocolo de trazabilidad
        
        **Contactos de emergencia:**
        - Supervisor de Calidad: Ext. 1234
        - Mantenimiento: Ext. 5678
        - Laboratorio: Ext. 9012
        - Gerente de Producci√≥n: Ext. 4567
        
        **Ubicaci√≥n de equipos de emergencia:**
        - Kit de muestreo: Armario A-123
        - Documentaci√≥n de respaldo: Oficina de calidad
        - Equipo de medici√≥n port√°til: Laboratorio principal
        """)

    # Nueva secci√≥n: Mantenimiento y Calibraci√≥n
    with st.sidebar.expander("üîß Mantenimiento y Calibraci√≥n"):
        st.write("""
        **Calendario de Calibraci√≥n:**
        - Sensores de temperatura: Cada 48 horas
        - Medidores de pH: Calibraci√≥n diaria
        - Dens√≠metros: Calibraci√≥n semanal
        
        **Mantenimiento Preventivo:**
        - Limpieza de sensores: Cada 8 horas
        - Verificaci√≥n de conexiones: Cada 24 horas
        - Backup de datos: Autom√°tico cada 4 horas
        
        **Registro de Calibraci√≥n:**
        Documentar toda calibraci√≥n en el sistema MES
        usando el formato: CAL-YYYY-MM-DD-EQUIPO
        """)

    # Nueva secci√≥n: Normativas y Cumplimiento
    with st.sidebar.expander("üìã Normativas y Cumplimiento"):
        st.write("""
        **Est√°ndares Aplicables:**
        - ISO 9001:2015
        - HACCP
        - Normas espec√≠ficas de cervecer√≠a
        
        **Documentaci√≥n Requerida:**
        - Registro de lotes
        - Informes de calidad
        - Trazabilidad de ingredientes
        - Registros de temperatura
        
        **Auditor√≠as:**
        - Internas: Mensual
        - Externas: Trimestral
        - Registro sanitario: Anual
        """)

    # Controles de simulaci√≥n
    simulate_alert_button = st.sidebar.button("Simular Alerta de Calidad")
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Monitor de Calidad en Tiempo Real")
        st.write("""
        Este gr√°fico muestra las predicciones de calidad para cada lote en tiempo real.
        Las fluctuaciones significativas pueden indicar problemas en el proceso de producci√≥n.
        
        **Indicadores clave:**
        - L√≠nea verde: Calidad √≥ptima
        - L√≠nea amarilla: Zona de precauci√≥n
        - L√≠nea roja: L√≠mite de control
        """)
    
    with col2:
        st.subheader("Par√°metros Cr√≠ticos")
        st.info("""
        üå°Ô∏è Temperatura: 18-22¬∞C
        üìä pH: 4.0-6.0
        üîÑ Tiempo de Fermentaci√≥n: 72-96h
        üéØ Gravedad: 1.010-1.020
        ‚öñÔ∏è Ratio Malta:L√∫pulo: 70:30
        """)
        
        st.warning("""
        **L√≠mites de Control:**
        ‚ö†Ô∏è Variaci√≥n m√°x. temperatura: ¬±1.5¬∞C
        ‚ö†Ô∏è Variaci√≥n m√°x. pH: ¬±0.3
        ‚ö†Ô∏è Desviaci√≥n tiempo: ¬±4h
        """)

    # Initialize Spark, load model, and data once
    spark = initialize_spark_session()
    model = load_model(MODEL_PATH)
    df_full = load_and_preprocess_data(spark, DATA_PATH)

    # Placeholders for dynamic Streamlit elements
    chart_placeholder = st.empty()
    metrics_placeholder = st.empty()
    table_placeholder = st.empty()
    alert_placeholder = st.empty()

    if simulate_alert_button:
        alert_placeholder.error("""
        üö® ¬°ALERTA DE CALIDAD ACTIVADA!
        
        √öltimo lote requiere revisi√≥n inmediata.
        - Verificar par√°metros de temperatura
        - Revisar niveles de pH
        - Comprobar ratios de ingredientes
        
        Contacte al supervisor de calidad: Ext. 1234
        """)

    st.sidebar.success("Simulaci√≥n en curso...") # Indicate simulation is active

    # Initialize chart with an appropriate y-axis for predictions
    initial_chart_data = pd.DataFrame({'Puntuaci√≥n de Calidad': [0.0, 1.0]}) 
    chart = chart_placeholder.line_chart(initial_chart_data)

    # Main simulation loop
    while True:
        df_display_batch = process_batch(df_full, model, SIMULATION_BATCH_SIZE)
        pdf_batch_display = df_display_batch.toPandas()

        # Update metrics
        with metrics_placeholder.container():
            m1, m2, m3 = st.columns(3)
            m1.metric("Temperatura Promedio", f"{pdf_batch_display['Temperature'].mean():.1f}¬∞C")
            m2.metric("pH Promedio", f"{pdf_batch_display['pH_Level'].mean():.2f}")
            m3.metric("Calidad Predicha", f"{pdf_batch_display['prediction'].mean():.3f}")

        # Update chart
        chart.add_rows(pdf_batch_display[["prediction"]].rename(columns={'prediction': 'Puntuaci√≥n de Calidad'}))
            
        # Update table with formatted column names
        renamed_cols = {
            'Brew_Date': 'Fecha',
            'Temperature': 'Temperatura',
            'pH_Level': 'Nivel pH',
            'prediction': 'Predicci√≥n'
        }
        display_df = pdf_batch_display.rename(columns=renamed_cols)
        table_placeholder.dataframe(display_df)

        time.sleep(SIMULATION_SLEEP_INTERVAL)

if __name__ == "__main__":
    # This ensures main_app() is called only when the script is executed directly
    main_app()
